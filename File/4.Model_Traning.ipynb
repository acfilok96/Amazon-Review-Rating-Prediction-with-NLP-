{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_Review_Data_Spliting_And_Traning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDX2kUJdJIlv",
        "outputId": "6565e397-053c-439c-fe1f-db6c9f95a574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Connect to google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import data reading libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "U3BLbq-7YS5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load data and print \"x\" data\n",
        "\n",
        "loaded = np.load(\"/content/drive/MyDrive/Amazon/Amazon_100000_data/Amazon_text_to_numeric.npz\")\n",
        "x = loaded['a']\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtnn2daSYS3K",
        "outputId": "89c16f0a-a781-4779-e9ee-71ba6fc7fefc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   3  252 1471 ...    0    0    0]\n",
            " [  42 2093  108 ...    0    0    0]\n",
            " [ 219  400    5 ...    0    0    0]\n",
            " ...\n",
            " [   3   13 1755 ...    0    0    0]\n",
            " [ 170  177  627 ...    0    0    0]\n",
            " [  29  220   43 ...    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Print \"y\" data\n",
        "\n",
        "y = loaded['b']\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDDLp1y0YS0D",
        "outputId": "01be5998-faf9-4d79-874b-b994067c884d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 5 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Use categorical \n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnUGISqXZtRD",
        "outputId": "0010c259-c4dc-4d4e-f7a3-a482cc256f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Shuffle the data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(np.array(x),np.array(y),test_size=0.000001,random_state = 100)\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twc6b5CYYn32",
        "outputId": "3752278f-2094-400a-f637-5ae3eb7473fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99999, 933) (99999, 6)\n",
            "(1, 933) (1, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Activate GPU\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "with tf.device(device_name):\n",
        "  pass"
      ],
      "metadata": {
        "id": "v-OAyrbOZg23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "### Creating Model\n",
        "\n",
        "embedding_vector_features = 128\n",
        "voc_size = 16849\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim = voc_size, output_dim = embedding_vector_features, input_length = x_train.shape[1], mask_zero = True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(6,activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkmAwgnxgyrQ",
        "outputId": "ab03ed76-d4c3-4a33-db80-6f68dd0a42a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 933, 128)          2156672   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 933, 128)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               91600     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,248,878\n",
            "Trainable params: 2,248,878\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot the data\n",
        "\n",
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "lMY7XeHQg7CO",
        "outputId": "26a2f549-d74e-437d-c6e3-f6e60313ddbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train model and used k-fold data spliting way\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\n",
        "\n",
        "skf = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
        "\n",
        "i=1\n",
        "score = []\n",
        "with tf.device(device_name):\n",
        "  for train_index, test_index in skf.split(x_train, y_train):\n",
        "    print('\\n\\n',\"*\"*20,'\\n')\n",
        "    print(i)\n",
        "    i=i+1\n",
        "    print('\\n',\"*\"*20,'\\n\\n')\n",
        "    # print(y[train_index])\n",
        "    model.fit(x_train[train_index], y_train[train_index], epochs = 30, batch_size = 128, validation_data = (x_train[test_index], y_train[test_index]))\n",
        "    pred = model.predict(x_train[test_index])\n",
        "    # print(pred)\n",
        "    pred = np.array([np.argmax(i) for i in pred])\n",
        "    # print(pred)\n",
        "    true = np.array([np.argmax(i) for i in y_train[test_index]])\n",
        "    # print(true)\n",
        "    accu = accuracy_score(pred, true)\n",
        "    score.append(accu)\n",
        "    # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whQrdq6UYn0Z",
        "outputId": "c2f1afa1-6878-4d4b-88b7-b358a2d5c7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "1\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 59s 72ms/step - loss: 1.2334 - accuracy: 0.4658 - val_loss: 1.1302 - val_accuracy: 0.5303\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 1.0378 - accuracy: 0.5721 - val_loss: 1.1041 - val_accuracy: 0.5432\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.9408 - accuracy: 0.6226 - val_loss: 1.0917 - val_accuracy: 0.5598\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.8600 - accuracy: 0.6633 - val_loss: 1.1065 - val_accuracy: 0.5623\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.7895 - accuracy: 0.6932 - val_loss: 1.1191 - val_accuracy: 0.5679\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.7240 - accuracy: 0.7206 - val_loss: 1.1703 - val_accuracy: 0.5645\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.6657 - accuracy: 0.7449 - val_loss: 1.2015 - val_accuracy: 0.5761\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.6136 - accuracy: 0.7658 - val_loss: 1.2472 - val_accuracy: 0.5758\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.5646 - accuracy: 0.7855 - val_loss: 1.3361 - val_accuracy: 0.5744\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.5329 - accuracy: 0.7997 - val_loss: 1.4084 - val_accuracy: 0.5749\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.4918 - accuracy: 0.8153 - val_loss: 1.4952 - val_accuracy: 0.5785\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.4630 - accuracy: 0.8255 - val_loss: 1.5266 - val_accuracy: 0.5840\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.4267 - accuracy: 0.8416 - val_loss: 1.5844 - val_accuracy: 0.5786\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.4047 - accuracy: 0.8502 - val_loss: 1.6771 - val_accuracy: 0.5789\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.3817 - accuracy: 0.8597 - val_loss: 1.7550 - val_accuracy: 0.5824\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.3621 - accuracy: 0.8663 - val_loss: 1.7697 - val_accuracy: 0.5799\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.3404 - accuracy: 0.8743 - val_loss: 1.8104 - val_accuracy: 0.5863\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.3265 - accuracy: 0.8804 - val_loss: 1.8799 - val_accuracy: 0.5794\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.3153 - accuracy: 0.8847 - val_loss: 1.9081 - val_accuracy: 0.5813\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.2924 - accuracy: 0.8943 - val_loss: 1.9367 - val_accuracy: 0.5800\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.2755 - accuracy: 0.9001 - val_loss: 2.0999 - val_accuracy: 0.5827\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2707 - accuracy: 0.9016 - val_loss: 2.0474 - val_accuracy: 0.5788\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2539 - accuracy: 0.9084 - val_loss: 2.0963 - val_accuracy: 0.5795\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2429 - accuracy: 0.9131 - val_loss: 2.1204 - val_accuracy: 0.5824\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2375 - accuracy: 0.9154 - val_loss: 2.2099 - val_accuracy: 0.5860\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2198 - accuracy: 0.9223 - val_loss: 2.2257 - val_accuracy: 0.5906\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2109 - accuracy: 0.9249 - val_loss: 2.3385 - val_accuracy: 0.5898\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2062 - accuracy: 0.9263 - val_loss: 2.2620 - val_accuracy: 0.5851\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.1948 - accuracy: 0.9304 - val_loss: 2.3032 - val_accuracy: 0.5826\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1940 - accuracy: 0.9315 - val_loss: 2.3971 - val_accuracy: 0.5844\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "2\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.3785 - accuracy: 0.8958 - val_loss: 0.1409 - val_accuracy: 0.9624\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.3024 - accuracy: 0.9072 - val_loss: 0.1637 - val_accuracy: 0.9481\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.2662 - accuracy: 0.9157 - val_loss: 0.1809 - val_accuracy: 0.9371\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.2410 - accuracy: 0.9229 - val_loss: 0.2142 - val_accuracy: 0.9222\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.2175 - accuracy: 0.9288 - val_loss: 0.2470 - val_accuracy: 0.9119\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.2035 - accuracy: 0.9331 - val_loss: 0.2746 - val_accuracy: 0.9040\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1943 - accuracy: 0.9349 - val_loss: 0.3106 - val_accuracy: 0.8870\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1818 - accuracy: 0.9386 - val_loss: 0.3573 - val_accuracy: 0.8780\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1705 - accuracy: 0.9428 - val_loss: 0.3952 - val_accuracy: 0.8702\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1593 - accuracy: 0.9458 - val_loss: 0.4389 - val_accuracy: 0.8619\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.1531 - accuracy: 0.9483 - val_loss: 0.4543 - val_accuracy: 0.8554\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1485 - accuracy: 0.9491 - val_loss: 0.4834 - val_accuracy: 0.8528\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1452 - accuracy: 0.9508 - val_loss: 0.5193 - val_accuracy: 0.8429\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1359 - accuracy: 0.9530 - val_loss: 0.5652 - val_accuracy: 0.8356\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1287 - accuracy: 0.9566 - val_loss: 0.5975 - val_accuracy: 0.8275\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1300 - accuracy: 0.9558 - val_loss: 0.6030 - val_accuracy: 0.8221\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1256 - accuracy: 0.9583 - val_loss: 0.6535 - val_accuracy: 0.8176\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1216 - accuracy: 0.9593 - val_loss: 0.6735 - val_accuracy: 0.8148\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.1170 - accuracy: 0.9602 - val_loss: 0.7126 - val_accuracy: 0.8095\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1113 - accuracy: 0.9622 - val_loss: 0.7456 - val_accuracy: 0.8061\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1081 - accuracy: 0.9630 - val_loss: 0.8015 - val_accuracy: 0.7986\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1053 - accuracy: 0.9644 - val_loss: 0.8053 - val_accuracy: 0.7959\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1037 - accuracy: 0.9652 - val_loss: 0.8314 - val_accuracy: 0.7902\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0983 - accuracy: 0.9666 - val_loss: 0.8917 - val_accuracy: 0.7907\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0979 - accuracy: 0.9661 - val_loss: 0.9134 - val_accuracy: 0.7835\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0955 - accuracy: 0.9675 - val_loss: 0.9410 - val_accuracy: 0.7804\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0937 - accuracy: 0.9685 - val_loss: 0.9781 - val_accuracy: 0.7801\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0916 - accuracy: 0.9694 - val_loss: 0.9799 - val_accuracy: 0.7765\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0911 - accuracy: 0.9689 - val_loss: 1.0197 - val_accuracy: 0.7674\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0902 - accuracy: 0.9693 - val_loss: 1.0476 - val_accuracy: 0.7679\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "3\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1952 - accuracy: 0.9438 - val_loss: 0.0346 - val_accuracy: 0.9923\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1403 - accuracy: 0.9559 - val_loss: 0.0361 - val_accuracy: 0.9897\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.1224 - accuracy: 0.9604 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1120 - accuracy: 0.9627 - val_loss: 0.0498 - val_accuracy: 0.9826\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.1038 - accuracy: 0.9659 - val_loss: 0.0618 - val_accuracy: 0.9803\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0986 - accuracy: 0.9664 - val_loss: 0.0668 - val_accuracy: 0.9759\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0946 - accuracy: 0.9681 - val_loss: 0.0782 - val_accuracy: 0.9714\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0927 - accuracy: 0.9686 - val_loss: 0.0904 - val_accuracy: 0.9684\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 0.0997 - val_accuracy: 0.9644\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0857 - accuracy: 0.9708 - val_loss: 0.1058 - val_accuracy: 0.9654\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0837 - accuracy: 0.9715 - val_loss: 0.1184 - val_accuracy: 0.9592\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0830 - accuracy: 0.9719 - val_loss: 0.1348 - val_accuracy: 0.9548\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0811 - accuracy: 0.9732 - val_loss: 0.1488 - val_accuracy: 0.9502\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0779 - accuracy: 0.9732 - val_loss: 0.1635 - val_accuracy: 0.9462\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0765 - accuracy: 0.9742 - val_loss: 0.1700 - val_accuracy: 0.9441\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0753 - accuracy: 0.9749 - val_loss: 0.1868 - val_accuracy: 0.9359\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.2003 - val_accuracy: 0.9360\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0726 - accuracy: 0.9755 - val_loss: 0.2166 - val_accuracy: 0.9315\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0686 - accuracy: 0.9766 - val_loss: 0.2391 - val_accuracy: 0.9276\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0703 - accuracy: 0.9764 - val_loss: 0.2415 - val_accuracy: 0.9243\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0693 - accuracy: 0.9765 - val_loss: 0.2524 - val_accuracy: 0.9234\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0652 - accuracy: 0.9779 - val_loss: 0.2645 - val_accuracy: 0.9187\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.0686 - accuracy: 0.9774 - val_loss: 0.2840 - val_accuracy: 0.9161\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.2895 - val_accuracy: 0.9124\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0668 - accuracy: 0.9776 - val_loss: 0.3282 - val_accuracy: 0.9064\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0624 - accuracy: 0.9789 - val_loss: 0.3389 - val_accuracy: 0.9055\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0635 - accuracy: 0.9785 - val_loss: 0.3433 - val_accuracy: 0.9008\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0634 - accuracy: 0.9791 - val_loss: 0.3809 - val_accuracy: 0.8954\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0623 - accuracy: 0.9794 - val_loss: 0.3755 - val_accuracy: 0.8956\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0614 - accuracy: 0.9795 - val_loss: 0.3931 - val_accuracy: 0.8912\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "4\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.1162 - accuracy: 0.9650 - val_loss: 0.0108 - val_accuracy: 0.9974\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0866 - accuracy: 0.9716 - val_loss: 0.0126 - val_accuracy: 0.9967\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0787 - accuracy: 0.9735 - val_loss: 0.0153 - val_accuracy: 0.9959\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0693 - accuracy: 0.9761 - val_loss: 0.0193 - val_accuracy: 0.9936\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0697 - accuracy: 0.9766 - val_loss: 0.0238 - val_accuracy: 0.9923\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 0.0262 - val_accuracy: 0.9913\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0647 - accuracy: 0.9783 - val_loss: 0.0334 - val_accuracy: 0.9900\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0624 - accuracy: 0.9788 - val_loss: 0.0324 - val_accuracy: 0.9886\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0613 - accuracy: 0.9793 - val_loss: 0.0489 - val_accuracy: 0.9843\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0610 - accuracy: 0.9798 - val_loss: 0.0449 - val_accuracy: 0.9854\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0601 - accuracy: 0.9800 - val_loss: 0.0486 - val_accuracy: 0.9836\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0577 - accuracy: 0.9807 - val_loss: 0.0481 - val_accuracy: 0.9832\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.0588 - val_accuracy: 0.9806\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0592 - accuracy: 0.9804 - val_loss: 0.0674 - val_accuracy: 0.9772\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.0770 - val_accuracy: 0.9760\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0826 - val_accuracy: 0.9732\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0546 - accuracy: 0.9816 - val_loss: 0.0898 - val_accuracy: 0.9708\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0554 - accuracy: 0.9817 - val_loss: 0.0917 - val_accuracy: 0.9696\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.1037 - val_accuracy: 0.9652\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.1206 - val_accuracy: 0.9615\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 0.1262 - val_accuracy: 0.9581\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0519 - accuracy: 0.9828 - val_loss: 0.1342 - val_accuracy: 0.9575\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0513 - accuracy: 0.9826 - val_loss: 0.1442 - val_accuracy: 0.9564\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0512 - accuracy: 0.9826 - val_loss: 0.1475 - val_accuracy: 0.9527\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0514 - accuracy: 0.9831 - val_loss: 0.1486 - val_accuracy: 0.9541\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.0484 - accuracy: 0.9838 - val_loss: 0.1622 - val_accuracy: 0.9486\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.1714 - val_accuracy: 0.9453\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.0464 - accuracy: 0.9845 - val_loss: 0.1784 - val_accuracy: 0.9467\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 0.1949 - val_accuracy: 0.9409\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.1961 - val_accuracy: 0.9402\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "5\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0914 - accuracy: 0.9720 - val_loss: 0.0063 - val_accuracy: 0.9989\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0673 - accuracy: 0.9780 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0626 - accuracy: 0.9798 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.0099 - val_accuracy: 0.9971\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0544 - accuracy: 0.9817 - val_loss: 0.0109 - val_accuracy: 0.9964\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.0136 - val_accuracy: 0.9962\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.0149 - val_accuracy: 0.9957\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 0.0174 - val_accuracy: 0.9943\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.0173 - val_accuracy: 0.9953\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0527 - accuracy: 0.9828 - val_loss: 0.0244 - val_accuracy: 0.9922\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0500 - accuracy: 0.9836 - val_loss: 0.0284 - val_accuracy: 0.9915\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0512 - accuracy: 0.9832 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0491 - accuracy: 0.9835 - val_loss: 0.0354 - val_accuracy: 0.9895\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0484 - accuracy: 0.9840 - val_loss: 0.0353 - val_accuracy: 0.9883\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0485 - accuracy: 0.9842 - val_loss: 0.0374 - val_accuracy: 0.9870\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 0.0456 - val_accuracy: 0.9848\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.0503 - val_accuracy: 0.9843\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0471 - accuracy: 0.9845 - val_loss: 0.0470 - val_accuracy: 0.9844\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 0.0546 - val_accuracy: 0.9822\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0453 - accuracy: 0.9856 - val_loss: 0.0601 - val_accuracy: 0.9803\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0606 - val_accuracy: 0.9811\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.0425 - accuracy: 0.9863 - val_loss: 0.0638 - val_accuracy: 0.9786\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 48s 68ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0642 - val_accuracy: 0.9779\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0460 - accuracy: 0.9851 - val_loss: 0.0753 - val_accuracy: 0.9757\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 48s 69ms/step - loss: 0.0425 - accuracy: 0.9859 - val_loss: 0.0767 - val_accuracy: 0.9749\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.0862 - val_accuracy: 0.9733\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0430 - accuracy: 0.9856 - val_loss: 0.0901 - val_accuracy: 0.9715\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0452 - accuracy: 0.9851 - val_loss: 0.0971 - val_accuracy: 0.9686\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.1093 - val_accuracy: 0.9648\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 0.1169 - val_accuracy: 0.9627\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "6\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0723 - accuracy: 0.9771 - val_loss: 0.0025 - val_accuracy: 0.9997\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0585 - accuracy: 0.9804 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0494 - accuracy: 0.9838 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.0060 - val_accuracy: 0.9978\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0463 - accuracy: 0.9846 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0487 - accuracy: 0.9837 - val_loss: 0.0111 - val_accuracy: 0.9965\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0114 - val_accuracy: 0.9959\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0438 - accuracy: 0.9856 - val_loss: 0.0135 - val_accuracy: 0.9965\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.0151 - val_accuracy: 0.9955\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 49s 69ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.0178 - val_accuracy: 0.9940\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0421 - accuracy: 0.9858 - val_loss: 0.0172 - val_accuracy: 0.9939\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0417 - accuracy: 0.9863 - val_loss: 0.0219 - val_accuracy: 0.9931\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0415 - accuracy: 0.9864 - val_loss: 0.0260 - val_accuracy: 0.9917\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0433 - accuracy: 0.9856 - val_loss: 0.0265 - val_accuracy: 0.9917\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.0278 - val_accuracy: 0.9904\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0298 - val_accuracy: 0.9896\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0315 - val_accuracy: 0.9896\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 0.0347 - val_accuracy: 0.9882\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0387 - val_accuracy: 0.9867\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.0483 - val_accuracy: 0.9852\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0448 - val_accuracy: 0.9848\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0475 - val_accuracy: 0.9841\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0376 - accuracy: 0.9876 - val_loss: 0.0531 - val_accuracy: 0.9811\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0382 - accuracy: 0.9875 - val_loss: 0.0581 - val_accuracy: 0.9798\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0384 - accuracy: 0.9873 - val_loss: 0.0573 - val_accuracy: 0.9807\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.0660 - val_accuracy: 0.9775\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0724 - val_accuracy: 0.9765\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "7\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 0.0027 - val_accuracy: 0.9994\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 0.0038 - val_accuracy: 0.9986\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0422 - accuracy: 0.9863 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0414 - accuracy: 0.9864 - val_loss: 0.0042 - val_accuracy: 0.9989\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 0.0079 - val_accuracy: 0.9978\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0082 - val_accuracy: 0.9976\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0407 - accuracy: 0.9869 - val_loss: 0.0103 - val_accuracy: 0.9967\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.0094 - val_accuracy: 0.9972\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0381 - accuracy: 0.9877 - val_loss: 0.0099 - val_accuracy: 0.9970\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.0157 - val_accuracy: 0.9952\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 0.0169 - val_accuracy: 0.9948\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.0368 - accuracy: 0.9883 - val_loss: 0.0213 - val_accuracy: 0.9934\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0374 - accuracy: 0.9877 - val_loss: 0.0211 - val_accuracy: 0.9927\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0362 - accuracy: 0.9877 - val_loss: 0.0233 - val_accuracy: 0.9920\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.0264 - val_accuracy: 0.9917\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.0291 - val_accuracy: 0.9920\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0367 - accuracy: 0.9881 - val_loss: 0.0286 - val_accuracy: 0.9900\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.0314 - val_accuracy: 0.9908\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.0334 - val_accuracy: 0.9883\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 0.0340 - val_accuracy: 0.9896\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0358 - accuracy: 0.9883 - val_loss: 0.0341 - val_accuracy: 0.9887\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0370 - val_accuracy: 0.9886\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.0385 - val_accuracy: 0.9882\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 0.0376 - val_accuracy: 0.9893\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "8\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0412 - accuracy: 0.9866 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0409 - accuracy: 0.9872 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0365 - accuracy: 0.9881 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 0.0080 - val_accuracy: 0.9984\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 0.0096 - val_accuracy: 0.9974\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 0.0087 - val_accuracy: 0.9979\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0354 - accuracy: 0.9885 - val_loss: 0.0103 - val_accuracy: 0.9968\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.0105 - val_accuracy: 0.9969\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0358 - accuracy: 0.9885 - val_loss: 0.0124 - val_accuracy: 0.9965\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.0148 - val_accuracy: 0.9960\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.0163 - val_accuracy: 0.9947\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.0178 - val_accuracy: 0.9947\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.0198 - val_accuracy: 0.9939\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 0.0215 - val_accuracy: 0.9932\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0263 - val_accuracy: 0.9912\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 0.0253 - val_accuracy: 0.9920\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0275 - val_accuracy: 0.9909\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.0280 - val_accuracy: 0.9907\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.0317 - val_accuracy: 0.9888\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.0366 - val_accuracy: 0.9884\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.0317 - val_accuracy: 0.9900\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.0359 - val_accuracy: 0.9894\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 0.0388 - val_accuracy: 0.9877\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "9\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0447 - accuracy: 0.9859 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 49s 70ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 0.0024 - val_accuracy: 0.9991\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 50s 70ms/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 0.0061 - val_accuracy: 0.9987\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0361 - accuracy: 0.9880 - val_loss: 0.0063 - val_accuracy: 0.9981\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 0.0069 - val_accuracy: 0.9978\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.0360 - accuracy: 0.9882 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 0.0105 - val_accuracy: 0.9971\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0326 - accuracy: 0.9896 - val_loss: 0.0109 - val_accuracy: 0.9966\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.0337 - accuracy: 0.9891 - val_loss: 0.0121 - val_accuracy: 0.9962\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 0.0121 - val_accuracy: 0.9951\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 50s 71ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0117 - val_accuracy: 0.9963\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.0126 - val_accuracy: 0.9962\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 50s 72ms/step - loss: 0.0323 - accuracy: 0.9890 - val_loss: 0.0147 - val_accuracy: 0.9955\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.0168 - val_accuracy: 0.9940\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 0.0156 - val_accuracy: 0.9949\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0187 - val_accuracy: 0.9942\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.0211 - val_accuracy: 0.9927\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.0200 - val_accuracy: 0.9937\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.0262 - val_accuracy: 0.9913\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 0.0246 - val_accuracy: 0.9926\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.0280 - val_accuracy: 0.9908\n",
            "\n",
            "\n",
            " ******************** \n",
            "\n",
            "10\n",
            "\n",
            " ******************** \n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.0019 - val_accuracy: 0.9992\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 53s 75ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.0024 - val_accuracy: 0.9992\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 52s 73ms/step - loss: 0.0360 - accuracy: 0.9885 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 52s 73ms/step - loss: 0.0334 - accuracy: 0.9891 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 52s 74ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0061 - val_accuracy: 0.9982\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0071 - val_accuracy: 0.9981\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.0098 - val_accuracy: 0.9972\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 52s 74ms/step - loss: 0.0321 - accuracy: 0.9898 - val_loss: 0.0098 - val_accuracy: 0.9973\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0314 - accuracy: 0.9898 - val_loss: 0.0117 - val_accuracy: 0.9972\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.0119 - val_accuracy: 0.9971\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.0164 - val_accuracy: 0.9955\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 52s 74ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.0129 - val_accuracy: 0.9964\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0164 - val_accuracy: 0.9961\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.0173 - val_accuracy: 0.9957\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0165 - val_accuracy: 0.9954\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.0210 - val_accuracy: 0.9931\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.0208 - val_accuracy: 0.9937\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.0213 - val_accuracy: 0.9930\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.0206 - val_accuracy: 0.9934\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 51s 73ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0238 - val_accuracy: 0.9924\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0267 - val_accuracy: 0.9925\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 51s 72ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.0256 - val_accuracy: 0.9920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Predicting model\n",
        "\n",
        "print(np.array(score).mean())"
      ],
      "metadata": {
        "id": "7yYtRQeciQq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save the model\n",
        "\n",
        "model.save('/content/drive/MyDrive/Amazon/Amazon_100000_data/model_1.h5')"
      ],
      "metadata": {
        "id": "UaNlPQZGYnxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}